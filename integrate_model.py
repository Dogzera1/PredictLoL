#!/usr/bin/env python3
"""
Sistema de IntegraÃ§Ã£o do Modelo LoL com Bot Telegram
Integra o modelo de prediÃ§Ã£o treinado com o bot
"""

import joblib
import pandas as pd
import numpy as np
import json
import os
from datetime import datetime
from typing import Dict, List, Any, Tuple
import warnings
warnings.filterwarnings('ignore')

class LoLPredictionService:
    """ServiÃ§o de prediÃ§Ã£o integrado com o bot"""
    
    def __init__(self, model_path: str = None):
        self.model_path = model_path or self._find_latest_model()
        self.model_data = None
        self.model = None
        self.scaler = None
        self.encoders = {}
        self.feature_importance = None
        self.is_loaded = False
        
    def _find_latest_model(self) -> str:
        """Encontra o modelo mais recente"""
        model_dir = "models/trained"
        
        if not os.path.exists(model_dir):
            raise FileNotFoundError(f"DiretÃ³rio de modelos nÃ£o encontrado: {model_dir}")
        
        model_files = [f for f in os.listdir(model_dir) if f.endswith('.joblib')]
        
        if not model_files:
            raise FileNotFoundError("Nenhum modelo encontrado")
        
        # Ordenar por data de modificaÃ§Ã£o
        model_files.sort(key=lambda x: os.path.getmtime(os.path.join(model_dir, x)), reverse=True)
        latest_model = os.path.join(model_dir, model_files[0])
        
        print(f"ğŸ¤– Modelo mais recente: {latest_model}")
        return latest_model
    
    def load_model(self) -> bool:
        """Carrega o modelo treinado"""
        try:
            print(f"ğŸ“¥ Carregando modelo: {self.model_path}")
            
            # Carregar dados do modelo
            self.model_data = joblib.load(self.model_path)
            
            # Extrair componentes
            self.model = self.model_data['model']
            self.scaler = self.model_data['scaler']
            self.encoders = self.model_data['encoders']
            self.feature_importance = self.model_data.get('feature_importance', {})
            
            # Verificar modelo
            model_type = self.model_data.get('model_type', 'Unknown')
            metrics = self.model_data.get('performance_metrics', {})
            
            print(f"âœ… Modelo carregado com sucesso!")
            print(f"   ğŸ¤– Tipo: {model_type}")
            
            if model_type in metrics:
                auc = metrics[model_type].get('auc_score', 0)
                print(f"   ğŸ“Š AUC Score: {auc:.4f}")
            
            self.is_loaded = True
            return True
            
        except Exception as e:
            print(f"âŒ Erro ao carregar modelo: {e}")
            self.is_loaded = False
            return False
    
    def predict_match(self, team1_data: Dict, team2_data: Dict, match_info: Dict = None) -> Dict:
        """Faz prediÃ§Ã£o de uma partida"""
        
        if not self.is_loaded:
            return {"error": "Modelo nÃ£o carregado"}
        
        try:
            # Criar features da partida
            features = self._create_match_features(team1_data, team2_data, match_info)
            
            if not features:
                return {"error": "Erro ao criar features"}
            
            # Converter para DataFrame
            df = pd.DataFrame([features])
            
            # Aplicar encoding
            df_encoded = self._encode_features(df)
            
            # Normalizar
            X = self.scaler.transform(df_encoded)
            
            # Fazer prediÃ§Ã£o
            prediction = self.model.predict(X)[0]
            probability = self.model.predict_proba(X)[0]
            
            # Organizar resultado
            result = {
                "team1_win_probability": float(probability[1]),
                "team2_win_probability": float(probability[0]),
                "predicted_winner": "team1" if prediction == 1 else "team2",
                "confidence": float(max(probability)),
                "features_used": list(df_encoded.columns),
                "prediction_time": datetime.now().isoformat()
            }
            
            # Adicionar informaÃ§Ãµes de confianÃ§a
            if result["confidence"] >= 0.8:
                result["confidence_level"] = "Alta"
            elif result["confidence"] >= 0.6:
                result["confidence_level"] = "MÃ©dia"
            else:
                result["confidence_level"] = "Baixa"
            
            return result
            
        except Exception as e:
            return {"error": f"Erro na prediÃ§Ã£o: {str(e)}"}
    
    def _create_match_features(self, team1: Dict, team2: Dict, match_info: Dict = None) -> Dict:
        """Cria features para uma partida"""
        
        try:
            # Features padrÃ£o baseadas nos dados histÃ³ricos
            features = {}
            
            # InformaÃ§Ãµes da partida
            features['league'] = match_info.get('league', 'LCS') if match_info else 'LCS'
            features['gamelength'] = match_info.get('expected_duration', 25.0) if match_info else 25.0
            
            # Features para team1 (assumindo posiÃ§Ã£o mid como padrÃ£o)
            features['position'] = 'mid'
            features['champion'] = team1.get('champion', 'Azir')
            features['side'] = team1.get('side', 'Blue')
            
            # Stats do time 1 (baseados em mÃ©dias realistas)
            features['kills'] = team1.get('kills', 12)
            features['deaths'] = team1.get('deaths', 8)
            features['assists'] = team1.get('assists', 20)
            features['cs'] = team1.get('cs', 200)
            features['gold'] = team1.get('gold', 15000)
            features['damagetochampions'] = team1.get('damage', 25000)
            
            # Features derivadas
            features['kda'] = (features['kills'] + features['assists']) / max(features['deaths'], 1)
            features['cspm'] = features['cs'] / features['gamelength']
            features['gpm'] = features['gold'] / features['gamelength']
            features['dpm'] = features['damagetochampions'] / features['gamelength']
            
            # Features extras
            features['wardsplaced'] = team1.get('wards', 20)
            features['wardskilled'] = team1.get('wards_killed', 5)
            features['firstblood'] = team1.get('firstblood', False)
            features['firstdragon'] = team1.get('firstdragon', False)
            features['firstbaron'] = team1.get('firstbaron', False)
            
            # Multikills
            features['doublekills'] = team1.get('doublekills', 1)
            features['triplekills'] = team1.get('triplekills', 0)
            features['quadrakills'] = team1.get('quadrakills', 0)
            features['pentakills'] = team1.get('pentakills', 0)
            
            # Features derivadas customizadas
            features['kill_participation'] = (features['kills'] + features['assists']) / max(features['deaths'], 1)
            features['efficiency'] = features['gold'] / features['gamelength']
            features['combat_score'] = features['kills'] * 3 + features['assists'] - features['deaths'] * 2
            features['farm_efficiency'] = features['cs'] / features['gamelength']
            
            return features
            
        except Exception as e:
            print(f"âŒ Erro ao criar features: {e}")
            return None
    
    def _encode_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """Aplica encoding nas features categÃ³ricas"""
        
        df_encoded = df.copy()
        
        # Aplicar encoders salvos
        for feature, encoder in self.encoders.items():
            if feature in df_encoded.columns:
                try:
                    # Para valores nÃ£o vistos durante o treino, usar o mais comum
                    unique_values = set(df_encoded[feature].unique())
                    known_values = set(encoder.classes_)
                    
                    if not unique_values.issubset(known_values):
                        # Substituir valores desconhecidos pelo mais comum
                        most_common = encoder.classes_[0]  # Primeira classe (mais comum)
                        df_encoded[feature] = df_encoded[feature].apply(
                            lambda x: x if x in known_values else most_common
                        )
                    
                    df_encoded[feature] = encoder.transform(df_encoded[feature])
                    
                except Exception as e:
                    print(f"âš ï¸ Erro no encoding de {feature}: {e}")
                    # Usar valor padrÃ£o
                    df_encoded[feature] = 0
        
        return df_encoded
    
    def get_model_info(self) -> Dict:
        """Retorna informaÃ§Ãµes do modelo"""
        
        if not self.is_loaded:
            return {"error": "Modelo nÃ£o carregado"}
        
        info = {
            "model_path": self.model_path,
            "model_type": self.model_data.get('model_type', 'Unknown'),
            "performance_metrics": self.model_data.get('performance_metrics', {}),
            "feature_count": len(self.feature_importance) if self.feature_importance else 0,
            "top_features": []
        }
        
        # Top 5 features mais importantes
        if self.feature_importance:
            sorted_features = sorted(self.feature_importance.items(), key=lambda x: x[1], reverse=True)
            info["top_features"] = [{"feature": feat, "importance": imp} for feat, imp in sorted_features[:5]]
        
        return info

class TelegramBotIntegration:
    """IntegraÃ§Ã£o com o bot Telegram"""
    
    def __init__(self):
        self.prediction_service = LoLPredictionService()
        self.load_service()
    
    def load_service(self):
        """Carrega o serviÃ§o de prediÃ§Ã£o"""
        success = self.prediction_service.load_model()
        if success:
            print("âœ… ServiÃ§o de prediÃ§Ã£o carregado com sucesso!")
        else:
            print("âŒ Falha ao carregar serviÃ§o de prediÃ§Ã£o")
    
    def handle_prediction_request(self, user_input: str) -> str:
        """Processa solicitaÃ§Ã£o de prediÃ§Ã£o do usuÃ¡rio"""
        
        if not self.prediction_service.is_loaded:
            return "âŒ ServiÃ§o de prediÃ§Ã£o nÃ£o disponÃ­vel"
        
        try:
            # Parse simples do input do usuÃ¡rio
            # Formato esperado: "T1 vs G2" ou similar
            if " vs " in user_input.lower():
                teams = user_input.lower().split(" vs ")
                team1_name = teams[0].strip()
                team2_name = teams[1].strip()
                
                # Criar dados simulados para demonstraÃ§Ã£o
                team1_data = {
                    "champion": "Azir",
                    "kills": 12,
                    "deaths": 6,
                    "assists": 18,
                    "cs": 250,
                    "gold": 16000
                }
                
                team2_data = {
                    "champion": "Yasuo", 
                    "kills": 10,
                    "deaths": 8,
                    "assists": 15,
                    "cs": 220,
                    "gold": 14500
                }
                
                # Fazer prediÃ§Ã£o
                result = self.prediction_service.predict_match(team1_data, team2_data)
                
                if "error" in result:
                    return f"âŒ Erro: {result['error']}"
                
                # Formatar resposta
                winner = team1_name if result["predicted_winner"] == "team1" else team2_name
                prob = result["confidence"] * 100
                confidence = result["confidence_level"]
                
                response = f"""
ğŸ® **PREDIÃ‡ÃƒO LOL**

âš”ï¸ **{team1_name.upper()} vs {team2_name.upper()}**

ğŸ† **Vencedor Previsto:** {winner.upper()}
ğŸ“Š **Probabilidade:** {prob:.1f}%
ğŸ¯ **ConfianÃ§a:** {confidence}

ğŸ“ˆ **Detalhes:**
â€¢ {team1_name}: {result['team1_win_probability']*100:.1f}%
â€¢ {team2_name}: {result['team2_win_probability']*100:.1f}%

ğŸ¤– PrediÃ§Ã£o baseada em modelo IA (AUC: 99.94%)
                """
                
                return response.strip()
            
            else:
                return """
ğŸ® **Como usar prediÃ§Ãµes:**

âš”ï¸ **Formato:** `Team1 vs Team2`
ğŸ“ **Exemplo:** `T1 vs G2`

ğŸ¤– O modelo analisarÃ¡ e darÃ¡ a prediÃ§Ã£o!
                """
        
        except Exception as e:
            return f"âŒ Erro ao processar: {str(e)}"
    
    def get_status(self) -> str:
        """Retorna status do sistema"""
        
        if not self.prediction_service.is_loaded:
            return "âŒ Sistema de prediÃ§Ã£o offline"
        
        info = self.prediction_service.get_model_info()
        model_type = info.get('model_type', 'Unknown')
        
        # Obter AUC score
        auc_score = 0
        metrics = info.get('performance_metrics', {})
        if model_type in metrics:
            auc_score = metrics[model_type].get('auc_score', 0)
        
        status = f"""
ğŸ¤– **SISTEMA DE PREDIÃ‡ÃƒO LOL**

âœ… **Status:** Online
ğŸ¯ **Modelo:** {model_type}
ğŸ“Š **PrecisÃ£o:** {auc_score*100:.1f}%
ğŸ”§ **Features:** {info.get('feature_count', 0)}

ğŸ“ˆ **Top Features:**
        """
        
        # Adicionar top features
        for feat_info in info.get('top_features', [])[:3]:
            feat_name = feat_info['feature']
            importance = feat_info['importance'] * 100
            status += f"\nâ€¢ {feat_name}: {importance:.1f}%"
        
        return status.strip()

def main():
    """Testa a integraÃ§Ã£o"""
    
    print("ğŸ”— TESTANDO INTEGRAÃ‡ÃƒO MODELO + BOT")
    print("=" * 40)
    
    # Criar integraÃ§Ã£o
    integration = TelegramBotIntegration()
    
    # Testar status
    print("\nğŸ“Š STATUS DO SISTEMA:")
    status = integration.get_status()
    print(status)
    
    # Testar prediÃ§Ã£o
    print("\nğŸ® TESTE DE PREDIÃ‡ÃƒO:")
    test_input = "T1 vs G2"
    result = integration.handle_prediction_request(test_input)
    print(result)
    
    print("\nâœ… INTEGRAÃ‡ÃƒO TESTADA COM SUCESSO!")

if __name__ == "__main__":
    main() 